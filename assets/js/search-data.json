{
  
    
        "post0": {
            "title": "The Private AI Series, Course 1, Part 1",
            "content": "I started taking The Private AI Series by OpenMined . The series contains four courses, all are free. At the time of writing, only the first one is online. . Our Privacy Opportunity | Foundations of Private Computation | Federated Learning Across Enterprises | Federated Learning on Mobile | The first course is non-technical and contains about 8 hours of video, taught by Emma Bluemke and Andrew Trask. Additionally, they interview many experts. The course aims to provide an overview of what privacy means, where it currently fails, and how possible solutions look like. One key point is that there are new privacy-enhancing technologies on the rise that will change the way how humans collaborate. This brings with it many career and business opportunities. . If you’re interested, sign up at courses.openmined.org! . Lesson 1 is just introductory. This is my summary of Lesson 2 of Our Privacy Opportunity. In addition, I can recommend Nahua Kang&#39;s great summary, it is more thouroughly structured than mine, which I primarily wrote for my forgetful self. . Society Runs on Information Flows . The main topic of the course is the privacy-transparency trade-off and how it affects a huge number of issues. This lesson walks through some of the most important challenges to society and identifies how the privacy-transparency trade-off underpins them. Improving information flows, by solving this trade-off, can help us in many areas like disinformation, scientific innovation, and even democracy itself. . Important: Every part of the human experience is soaked in information flows. Since the beginning of human collaboration. We share our medical information with our doctor, we share our location with an app to get directions, we share our heart rates and sleeping patterns in hopes of improving our well-being. Every day, we share personal information to exchange goods, receive services, and in general, to collaborate. Sharing information is a part of almost every aspect of our life. . Information Flow . What is an information flow? Let&#39;s take the simple example of email. A sender, a message, a receiver. Probably one of the most straight-forward information flows. But even email is much more nuanced than just the three attributes sender, message, receiver: . Should other people than the receiver be allowed to read it? | Would I be comfortable with the receiver forwarding my email? | The email provider could probably read it, do I trust them to not do so? | Do I want the email provider to read my mail only for a specific purpose, like for spam detection, but not for targeted advertising? | Am I sending my exact identity with the email? Anonymously? Or a mix: as a member of group? | Do I know exactly who the recipient is? When I&#39;m sending the mail to a doctor&#39;s office, who reads it? | Can the receiver have confidence in the identity of the sender, whaf if my account was hacked? | . Questions like these exist around every information flow. . Newly emerging communication channels: Snapchat deletes the messages once they&#39;ve been read and prohibits forwarding or screenshotting. WhatsApp or Signal use end-to-end encryption for messages so it&#39;s impossible for anyone other than the intended recipient to read them. Users switch to these services because of seemingly tiny changes to the guarantees around information flow. This is the beginning of a revolution! . Note: Definition: An information flow is a flow of bits from a sender to a receiver. The sender and receiver could either be an exact individual, a member of a group, or an anonymous individual. The identity of the sender, the receiver, and the content of the message itself can be probabilistic. The probabilistic nature is important. Often a piece of information you share does not have an exact recipient. . What Does Privacy Mean? . Privacy is not about secrecy. People feel that their privacy is violated if information flows in a way they didn&#39;t expect. It&#39;s all about the appropriate flow of information, not about the information itself. . Note: Privacy means the ability to ensure information flows that are according to social norms. Example: Google Street View: why are people having trouble with Google taking photos of them in their front yard, when anybody could come by and see them exactly there? Because when public information becomes so much more public, it bothers us. . Note: This theory of privacy is called Contextual Integrity: sharing the same information might be private in one context, but not in another context. It&#8217;s about achieving appropriate information flow. (There is a bit more to the concept, developed by Helen Nissenbaum, see details on Wikipedia) . Example: My face is considered public information as soon as I leave the house, because anybody can see it. So why is facial recognition software so troubling? Not only because it could be misused (i.e., for mass surveillance), but because it is identification without my consent. The information flow is not triggered by me, but by whatever system is watching me. . Data is Fire &#128293; . There is the popular notion that &quot;data is the new oil&quot;. A better analogy is &quot;data is fire&quot;. . It can be duplicated indefinitely | It can help us prosper and solve problems | It can cause irreparable damage if misused | . This dual-use for good or harm is true for all kinds of data, not just data that is clearly sensitive like medical data. . Everything can be private data . Your grocery shopping list is boring, right? Not always. You might not care now whether somebody knows you&#39;re buying bread. But when you suddenly stop buying bread (and other carbs), it might be an indication of the diagnosis of diabetes. Suddenly it&#39;s very private information that you might not want to share. . Careful: Anonymization doesn&#8217;t work! While anonymization seems like the obvious solution to protect the identities of people in data, this does not work reliably. Even when names are removed from data, other features can be used to identify you, thanks to the power of machine learning. . And even when your exact identity is not recoverable, data can be used for targeting: As long as someone is able to reach you (via your browser, your church, your neighborhood, ...), your name is not at all necessary to do harm. . Example: Anonymization works so badly, that systematically exploiting its weaknesses can become a business model. Emma talks about a US company that buys anonymized health data and distributes &quot;market insights&quot; from it to insurance companies. They can then, for example, avoid selling insurance to high-risk communities like poor neighborhoods, where people are more likely to get sick. . Another example: Strava released an anonymized heatmap of user activities that revealed the location of US military bases. So, privacy can be relevant not only on an individual level but on an organizational or even national security level. Strava released their global heatmap. 13 trillion GPS points from their users (turning off data sharing is an option). https://t.co/hA6jcxfBQI … It looks very pretty, but not amazing for Op-Sec. US Bases are clearly identifiable and mappable pic.twitter.com/rBgGnOzasq . &mdash; Nathan Ruser (@Nrg8000) January 27, 2018 . Privacy and Transparency Dilemmas . Remember the dual-use of data 🔥 from the previous section. Due to the potentially harmful use of data, we have to constantly make trade-offs and decide whether to share information, weighing the benefits and the risks. . Note: A privacy dilemma is a trade-off whether or not to reveal information, where revealing that information causes some social good (like advances in medical research) but could also lead to harm (like the misuse of medical data). Privacy dilemmas have various costs. The most obvious is a privacy violation where data is shared in good faith but the information is misused. On the other hand, there are societal costs when information instead is kept secret: a failure to accomplish important outcomes of information flow (scientific progress, meaningful relationships, accountability). . Tip: Privacy dilemmas are untapped market opportunities! Closely related is the transparency dilemma: . Note: A transparency dilemma is when someone is forced to make a decision without having access to the information they need to make it. Sometimes the necessary information flows don&#39;t exist at all (trusting a stranger to fix your tire), sometimes they exist but their content is not verified (online reviews). . Stopping all information flow and locking all data is not the solution to the privacy issue. This would prevent good use of data (think medical care, climate research) and also make undesirable behaviour easier (money laundering, lack of accountability). Maximizing privacy could lead to a lack of transparency! . The Privacy-Transparency Pareto Frontier . . This is the privacy-transparency trade-off. More of one means less of the other.We used to have a classic Pareto trade-off between privacy and transparency. You had to decide whether you share information at the cost of privacy (point A in the chart). Or whether you keep information private, but at the cost of transparency (B). The question is: how can we move the frontier of this trade-off and have more of both at the same time? . . With new privacy-enhancing technologies, we can have more of both privacy and transparency.With new technologies, we can actually move the pareto frontier and not have a zero-sum game anymore! This will affect every industry handling valuable, sensitive, or private data. . Thanks to these technologies, in the future governments won&#39;t have to choose between preserving the privacy of their citizens or protect national security, they can do both. Researchers won&#39;t have to decide whether or not to share their data, they can have the benefits from both. Corporations currently often have to choose between the privacy of their users and the accuracy of their products and services, in the future they can have both. . How these privacy-enhancing methods look like and which specific technologies are developed, will be covered later in the course. . Why We Need to Solve the Privacy-Transparency Trade-Off . Research is Constrained by Information Flows . If there was a way to share data across institutions while making sure it remained private and was used for good, all areas of research would benefit. More data would be available, it would be available faster, and also: experiments could be replicated more easily. . Healthy Market Competition for Information Services . Most services that handle your data will profit from locking you in. Because of privacy concerns they are inherently anti-competitive. More privacy restrictions can actually make it harder for new companies to compete (because you can&#39;t move your data from your old to the new provider). . We need more interoperability between information service providers. . Note: Interoperability means you can buy your shoes from one company and your socks from another. In information services it also means that you should be able to move to a different company and take your data with you. Example: Facebook actually started as a company that profited a lot from interoperability. One reason it gained popularity was that users from its established main competitor MySpace could connect their accounts with Facebook and still message with their friends on the old platform. Without this feature, probably less people would have switched to the new platform. This is called adversarial interoperability. . Note: The GDPR (General Data Protection Regulation) was introduced in the EU in 2018 and has the aim to give individuals control over their personal data. The GDPR is considered a groundbreaking piece of legislation and it is being copied around the world. . EU citizens now have 7 rights over their data, including the right to be forgotten (a company has to delete all your personal data on request) and the right of access (on request, companies have to send you a copy of all data they have of you). . Important: Privacy is not only about preventing information from being shared. Sometimes satisfying privacy is about forcing companies to share or delete your data in a specific way or at a specific time. . Data, Energy &amp; the Environment . One of society&#39;s biggest challenges is the transition to green energy. The volatile nature of renewable energy sources makes nation-wide coordination of energy demand necessary. . An area where the privacy-transparency trade-off comes into play is smart meters. Smart meters are highly valuable for the transition to clean energy. Grid operators can have an accurate picture of energy demand, consumers can reduce energy waste. But smart meters can also be extremely privacy invasive, because one can build rich patterns of your energy data. How your daily habits are, when you are or are not at home etc. . Example: In Taiwan many people have air boxes in their homes to measure pollution. There was a community-driven effort to collect these measurements. They were able to coordinate with millions of people to get this data-sharing system working. The government didn&#39;t invest heavily in this technology, but was very interested in the data. In exchange they installed more air boxes in places like public parks and military zones. . Important: The Taiwan example shows that collaboration of millions of people is possible and can solve urgent issues. . Feedback Mechanisms &amp; Information Flows . We often rely on the opinions of others when we make our decisions. Which car do you buy, which surgeon do you choose for a surgery? But there are more feedback mechanisms. Elections, protests, Facebook likes, going to prison, boycotting, gossip, are all feedback mechanisms. . Note: Feedback mechanism: Someone does something, and later gets positive or negative feedback from those affected by their actions. Feedback mechanisms help each entity in society understand how the world views the work they do so they can do more good things and fewer bad things. They are essential to society&#39;s function and unfortunately, due to the privacy-transparency trade-off, many of them are quite broken. This is the case when feedback information is too sensitive or valuable to be shared. . What does a broken F.M. scenario look like? . Examples: . Medical care: When you go for surgery, how good is your surgeon? Can you ask for reviews of previous patients, could you talk to previous nurses? And even if you could, could you talk to enough patients or nurses? | Consumer products: How do you know whether a product is any good? Amazon reviews are easy to fake, and the real ones come from only the most polarized users. | Politics: A multiple choice question between a few candidates every 4 years is a terrible feedback system for reviewing the legislature of the past 4 years. | . Most feedback information simply isn&#39;t collected, because it would be too personal to collect it. . Democracy &amp; Public Health Conversation . Democracy is messy. Opinions are formed via social groups. In recent years there was an uptick in polarization, one of the reasons probably being social media where algorithms maximize engagement. . A better way can be found in Taiwan, with the Polis system. A community-built, nation-wide application that supports conversation between millions of users in Taiwan. It&#39;s not optimized for engagement, but for consensus. People can enter their opinions in written form (tweet-like), and a combination of NLP and voting clusters these opinions. Turns out, opinions aren&#39;t actually individual. There are less opinions than there are people because opinions are formed socially. However, the social groups that form our opinions aren&#39;t fixed but constantly changing. . So, some people emerge as being representative for specific opinions and become thought leaders for this particular matter. But now they must come up with a formulation that will get the most consent across opinions. . Example: When Uber wanted to come to Taiwan, people had very polarized opinions. The solution was: Uber was permitted a temporary license in Taiwan. During this time, the public Taxi sector should adopt the efficient algorithmic approaches from Uber while maintaining current labor standards. If they would succeed, Uber would be banned. If they failed, Uber would be banned unless they met the labor standards of the public system. That put just enough pressure on both sides, and in the end, the public system did improve so much that Uber was excluded. . New Market Incentives . Many online companies use attention (often called engagement) as their key metric. For some this intuitively makes sense, because their revenue is ad-driven. But even companies that run on a subscription model, like Netflix, do it. Netflix&#39;s former CEO Reed Hastings famously said they are competing with sleep (&quot;And we’re winning!&quot;). The question is: why? . One answer is that it&#39;s a readily available metric which is fine-grained and allows for optimization. If Netflix just used the number of subscribers (and that&#39;s the value they actually try to increase), it would be too coarse. Only if a movie was so good or so bad that it made users subscribe/unsubscribe, it would have a measurable effect. . Attention as a metric does work and it is probably not a problem when used at a small scale. But at large scale and taken to the extremes it can cause harm, see the Netflix/sleep example. . Let&#39;s speculate about a better approach: Netflix could try to optimize their experience to improve the users&#39; sleep. But how would they measure it and train an algorithm on it? Fitbits track sleeping patterns, but is it safe to share this data with Netflix? In general, these alternative metrics are called wellness metrics and can improve our lives. . Tip: Technology isn&#8217;t inherently addictive! Better products are possible. But we need to solve the privacy-transparency trade-off. . Safe Data Networks for Business, Governance and R&amp;D . How do privacy-transparency trade-offs affect important public information flows? . The European Commission recently proposed the Data Governance Act to improve data flows around the EU. The motivation: Businesses need data. And if they want to customize their product for each member state, they need data from these states. Data should flow easily through the EU and should be used in the most effective and responsible manner. This increased access to data would advance scientific developments and innovations all across the EU. This is especially important where coordinated action is necessary, like a global pandemic or tackling climate change. . So why should data not flow entirely freely? . Commercially sensitive data like trade secrets should be protected. Data access can lead to theft of intellectual property. | Data is valuable. Not just for a business, but for a country. Who controls the data has an impact on national security. | Data can be private or sensitive. Fundamental rights of data protection have to be respected. | New threats to privacy: New mathematical tools allow reconstruction of personal details even from anonymized datasets. Free-flowing anonymized data access only seems like a good idea if you ignore all of the European history. . Technology advances faster than legislation. Regulation has to consider the power of future analysis techniques. . The privacy trade-off here is relevant to individuals, companies and countries. Companies and users should be able to trust that their data is used in a manner that respects their rights and interests. Trust will be crucial for data to be willingly shared. . But trust doesn&#39;t just arise. How can we protect the people&#39;s rights and interests? . Let&#39;s daydream: What if the data didn&#39;t have to move? What if the institutions within the home country had the only copy of a citizen&#39;s sensitive data, which the other countries accessed remotely and easily and in a controlled manner? Instead of transferring the data around Europe, out of the owner&#39;s control? . Today, there are new techniques to enable privacy-friendly analysis, including differential privacy which will be covered during this course. . Conflict, Political Science &amp; Information Flows . One rational explanation of war: Mutual Optimism. It&#39;s extremely hard to predict the outcome of a battle, a war. Both sides can come up with an estimate that says, &quot;we&#39;re more likely to win than not to win&quot;. The sum of the estimates is greater than 1. That&#39;s why nations go to war. . A way to share private military information to determine the winner (in a digital war game) ahead of time, but without actually giving away military secrets to the opponent, could potentially avoid wars. . This is true for other conflicts as well, like legal disputes or commercial competition. If the winner could be determined ahead some conflicts wouldn&#39;t be fought. . Moving the privacy-transparency trade-off is essential here as well. . Disinformation &amp; Information Flows . The flow of news is one of the most important information flows in the world. How do you know that what you read in the news is actually true? . Before the invention of the printing press, people had the power to talk to maybe 50 people at the same time. For a story to be shared outside your own social circle, you would have to convince other people to talk about it. But today, where the average person has hundreds of contacts on social media, fake news and rumors can spread easily. . How to check if news is true? . Have social media platforms emply people who check every bit that is published? Not feasible for hundreds of millions of users. | Let a machine learning algorithm check whether a piece of news is true? Probably a bad idea in the long run, because news are an information bottleneck. Detecting fake news only by reading it doesn&#39;t work, you have to have knowledge of the world. | Just get off social media? Maybe we&#39;re not supposed to be interconnected with that many people? | . The most interesting solution is currently being deployed in Taiwan: . The Polis platform (developed by a hacker collective called g0v, pronounced &quot;gov zero&quot;) aims to improve public discourse. Trained volunteers comment on suspicious stories with reliable sources one might check. Since these comments come from people you know from your local community, you already have a higher level of trust to them. . Important: We have to consider how societies historically dealt with misinformation. It doesn&#39;t fix the problem to let the platforms take down false posts. People are curious and won&#39;t just accept this as &quot;huh, this is false then&quot;. This is the beauty of Audrey Tang&#39;s work with g0v: constructing information flows that are healthy for society. Not thinking about the most efficient way to prevent a data flow. But to activate existing ways to fight disinformation: get people to help their friends. This might not seem as efficient, but will be more effective in the long run. . Another approach in Taiwan: using humor to foster trust between the state and its citizens. Humor over rumor! 🇹🇼 #Taiwan is combating #Coronavirus &amp; managing the #COVID19 pandemic.💡 Digital Social Innovation is key!🚀 It’s fast, open, fair &amp; fun.🙌 Most importantly, it needs #AllHandsOnDeck.🕔 Take 5 with me &amp; get up to speed.💻 Visit https://t.co/5D68ia7PcI &amp; learn much more. pic.twitter.com/M5ecPnSPLF . &mdash; Audrey Tang 唐鳳 (@audreyt) April 21, 2020 . Conclusion . The privacy-transparency trade-off or even privacy in general is in service of a higher aim: creating information flows within society that create social good. . Important: Privacy technology is not just about more privacy. Don&#39;t just look for use cases that scream &quot;privacy&quot;. Instead, ask yourself: How can society accomplish its goals with less risk, higher accuracy, faster, and with better aligned incentives than ever before, through better flows of information. . Tip: Entrepreneurial opportunities, regulatory opportunities, investing opportunities: It&#8217;s not about hiding data; it&#8217;s about enabling specific information flows (and just these!) to maximize social good. That is the promise of privacy-enhancing technology and has the potential to radically improve every aspect of how we share information. .",
            "url": "https://deeplearning.berlin/online%20courses/privacy/the%20private%20ai%20series/openmined/2021/01/06/Our-Privacy-Opportunity-Part-1.html",
            "relUrl": "/online%20courses/privacy/the%20private%20ai%20series/openmined/2021/01/06/Our-Privacy-Opportunity-Part-1.html",
            "date": " • Jan 6, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Understanding fastai's Midlevel API",
            "content": "Even after going through the course and book, I didn&#39;t feel comfortable with the numerous classes and methods that fastai offers for data processing. I felt that it would be easy once I understood it, but it just didn&#39;t click right away. So here I try to present the most important classes and why they are useful. . This is by no means a complete overview, but just an exploration with minimal examples. . For a deeper dive, please check out chapter 11 of fastbook, Wayde Gilliam&#39;s awesome blog post, or Zach Mueller&#39;s walk with fastai2. . Transforms . A Transform in general is an object that can be called (behaves like a function) and has an optional setup method that initializes an inner state, and an optional decode method that will reverse the function. . In general, our data is always in tuples of (input,target), although you can have more than one input or one target. When applying a transform, it should be applied to the elements of the tuple separately. . . . Note: Transforms are usually applied on tuples. . When you only want to implement the encoding behaviour of a transform, it can be defined via the @Transform decorator: . @Transform def lowercase(x:str): return str.lower(x) lowercase(&quot;Hello, Dear Reader&quot;) . &#39;hello, dear reader&#39; . Type dispatch . Transforms can be defined so they apply only to certain types. This concept is called type dispatch and is provided by fastcore, which I&#39;ll cover in a future post :-) . @Transform def square(x:int): return x**2 square((3, 3.)) . (9, 3.0) . Notice the type annotation for x. In this case, this is not merely a helpful annotation like in pure Python, but it actually changes the behaviour of the function! The square transform is only applied to elements of the type int. When we don&#39;t define the type, a transform is applied on all types. . A more complex transform . If you want to also define the setup and decode methods, you can inherit from Transform: . class DumbTokenizer(Transform): def setups(self, items): vocab = set([char for text in items for char in text]) self.c2i = {char: i for i, char in enumerate(vocab)} self.i2c = {i: char for i, char in enumerate(vocab)} def encodes(self, x): return [self.c2i.get(char, 999) for char in x] def decodes(self, x): return &#39;&#39;.join([self.i2c.get(n, &#39; ? &#39;) for n in x]) . texts = [&quot;Hello&quot;, &quot;Bonjour&quot;, &quot;Guten Tag&quot;, &quot;Konnichiwa&quot;] tokenizer = DumbTokenizer() tokenizer.setup(texts) encoded = tokenizer(&quot;Hello!&quot;) encoded . [9, 6, 2, 2, 4, 999] . Now this is a representation that a machine learning model can work with. But we humans can&#39;t read it anymore. To display the data and be able to analyze it, call decode on the result: . tokenizer.decode(encoded) . &#39;Hello ? &#39; . So here we defined a (very dumb) tokenizer. The setups method receives a bunch of items that we pass in. It creates a vocabulary of all characters that appear in items. In encodes we transform each character to a number in an index. When the character is not found in the vocabulary, it is replaced with a 999 token. decodes reverses this transform as good as it can. . Notice the ? in the decoded representation instead of !. Since there was no ! in the initial texts, the tokenizer replaced it with the token for &quot;unkown&quot;, 999. This is then replaced with ? during decoding. . By the way: you might have noticed that in the DumbTokenizer class we defined the methods setups, encodes and decodes, but on the instance tokenizer we call methods with slightly different names (setup, decode) or even the instance directly: tokenizer(...). The reason for this is that fastai applies some magic in the background, for example it checks that the type is not changed by the transforms. . Pipeline . A Pipeline is just an easy way to apply a list of transforms, in order. . tfms = Pipeline([lowercase, tokenizer]) encoded = tfms(&quot;Hello World!&quot;) encoded . [17, 6, 2, 2, 4, 11, 5, 4, 0, 2, 999, 999] . Pipeline also supports decoding of an item: . tfms.decode(encoded) . &#39;hello worl ? ? &#39; . Because we didn&#39;t define a decodes method for lowercase, this transform cannot be reversed. The decoded result consists only of lowercase letters. . What Pipeline doesn&#39;t provide is support for the setup of the transforms. When you want to apply a pipeline of transforms on a list of data, TfmdLists comes to the rescue. . TfmdLists . At first, your data is usually a set of raw items (like filenames or rows in a dataframe) to which you want to apply some transforms. To combine your pipeline of transforms with your set of raw items, use TfmdLists. . texts = [&quot;Hello&quot;, &quot;Bonjour&quot;, &quot;Guten Tag&quot;, &quot;Konnichiwa&quot;] tls = TfmdLists(texts, [DumbTokenizer]) . When initialized, TfmdLists will call the setup method of each Transform in order, providing it with all the items of the previous Transform. To get the result of the pipeline on any raw element, just index into the TfmdLists: . encoded = tls[1] encoded . [8, 4, 14, 15, 4, 19, 0] . tls.decode(encoded) . &#39;Bonjour&#39; . Training and validation sets . The reason that TfmdLists is named with an s (lists in plural) is that it can handle a training and a validation set. Use the splits argument to pass . the indices of the elements that should be in the training set | the indices of the elements that should be in the validation set. | . We will just do this by hand in our toy example. The training set will be &quot;Hello&quot; and &quot;Guten Tag&quot;, the other two go in the validation set. . texts = [&quot;Hello&quot;, &quot;Bonjour&quot;, &quot;Guten Tag&quot;, &quot;Konnichiwa&quot;] splits = [[0,2],[1,3]] tls = TfmdLists(texts, [lowercase, DumbTokenizer], splits=splits) . We can then access the sets through the train and valid attributes: . encoded = tls.train[1] encoded, tls.decode(encoded) . ([3, 7, 1, 6, 4, 8, 1, 0, 3], &#39;guten tag&#39;) . Let&#39;s look at at word in the validation set: . encoded = tls.valid[0] encoded, tls.decode(encoded) . ([999, 2, 4, 999, 2, 7, 999], &#39; ? on ? ou ? &#39;) . Ouch, what happened to our &quot;Bonjour&quot; here? When TfmdLists automatically called the setup method of the transforms, it only used the items of the training set. Since there was no b, j or r in our training data, the tokenizer treats them as unknown characters. . . Important: The setup methods of the transforms receive only the items of the training set. . Don&#39;t we need labels? . Maybe you noticed that we haven&#39;t dealt with tuples until now. We only have transformed our input, we don&#39;t have a target yet. . TfmdLists is useful when you built a custom Transform that performs data preprocessing and returns tuples of inputs and targets. You can apply further transforms if you want, and then create a DataLoaders object with the dataloaders method. . . Usually however, you will have two parallel pipelines of transforms - one to convert your raw items to inputs, and one to convert raw items to targets (ie labels). To do this we can use Datasets. . Datasets . To complete our quick tour through fastai&#39;s midlevel API, we look at the Datasets class. It applies two (or more) pipelines in parallel to a list of raw items and builds tuples of the results. It performs very much like a TfmdLists object, in that it . automatically does the setup of all Transforms | supports training and validation sets | supports indexing | . The main difference is: When we index into it, it returns a tuple with the results of each pipeline. . Let&#39;s look at how to use it. For this toy example, let&#39;s pretend we want to classify whether a text contains at least one space (that&#39;s a dumb example, I know). For this we create a little labelling function in the form of a Transform. . class SpaceLabeller(Transform): def encodes(self, x): return int(&#39; &#39; in x) def decodes(self, x): return bool(x) . x_tfms = [lowercase, DumbTokenizer] y_tfms = [SpaceLabeller] dsets = Datasets(texts, [x_tfms, y_tfms], splits=splits) item = dsets.valid[1] item . ([10, 14, 13, 13, 8, 2, 7, 8, 22, 0], 0) . dsets.decode(item) . (&#39;konnichiwa&#39;, False) . At last, we can create a DataLoaders object from the Datasets. To enable processing on the GPU, two small tweaks are required. First, every item has to be converted to a tensor (often this will happen earlier, as one of the transforms in the pipeline). Second, we use a fastai function called pad_input to make every sequence the same length, since a tensor requires regular shape. . dls = dsets.dataloaders(bs=1, after_item=tensor, before_batch=pad_input) . dls.train_ds . (#2) [([7, 4, 11, 11, 14], 0),([6, 20, 19, 4, 13, 999, 19, 0, 6], 1)] . This is now a ready-for-training dataloader! . Conclusion . We looked at how to customize every step of the data transformation pipeline. As mentioned in the beginning, this is not a complete description of all the features available, but a good starting point for experimentation. I hope this was helpful to you, let me know if you have questions or suggestions for improvement at hannes@deeplearning.berlin or @daflowjoe on Twitter. .",
            "url": "https://deeplearning.berlin/fastai/data%20processing/2020/12/16/Understanding-fastai-midlevel-API.html",
            "relUrl": "/fastai/data%20processing/2020/12/16/Understanding-fastai-midlevel-API.html",
            "date": " • Dec 16, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Getting started with fast.ai",
            "content": "Welcome! . Summary: I cover some questions you might have regarding the fast.ai course. Then, I offer some advice that would have helped me in the beginning. . Who is this article for? . If you&#39;re reading this article, I assume you have heard about the terms deep learning, machine learning, or artificial intelligence. Maybe you are not too sure what they mean specifically, but you want to know more. Maybe you&#39;ve been searching for a while to finally learn about these concepts, but are overwhelmed by the magnitude of courses, books and software available. . Whether you are a software developer planning to add a new skillset, a student wanting to broaden your horizon, or an expert in a completely different field and you want to apply AI in your company or project: The fast.ai online course can be great for you to get started, and it&#39;s completely free! . . About fast.ai . fast.ai is an organization committed to making deep learning more accessible. It was founded by Jeremy Howard and Rachel Thomas, both distinguished data scientists. . They offer four major elements that can help you get into deep learning. . fastai (notice the missing dot), a software library that allows creating powerful deep learning models with few lines of code, while nonetheless being very customizable. | A free online course based on the library. | A book that is designed to go hand in hand with the course. It&#39;s available as a paper book, as an e-book or even for free on Github. | A forum with a very helpful community. | . For me, what really sets fast.ai apart from other online courses, is their practical approach: . We [are] always teaching through examples. We ensure that there is a context and a purpose that you can understand intuitively, rather than starting with algebraic symbol manipulation. . This does not mean that the foundations are not covered (they are!), but the order is different than in other books or courses, where you start with basic tools and only get to usable applications at the end of the course - if ever. . What is covered in the course? . The course covers major applications of deep learning. There is a certain focus on computer vision, but the other topics like tabular data, natural language processing (NLP), and recommender systems are explained as well. You will be able to create very well performing models in all of these areas, and as early as lecture 2 you can create a working web app that can recognize grizzly bears and brown bears (or anything else you choose). . Later in the course, you will learn the foundations of deep learning. You&#39;ll write code for stochastic gradient descent and activation functions from scratch. Don&#39;t worry if you never have heard about these, it&#39;s explained very well. You will dig deeper into PyTorch, the underlying software of fastai. . Also, there is a lecture (and a chapter) on Data Ethics. It is taught by Rachel Thomas and will give you a lot of food for thought. I think it&#39;s great that fastai encourages you to think about the possible implications of your work early on. . Should I get the book? . Since the book is freely available online in the form of notebooks, you might be wondering if you should get the printed book anyway. My opinion: If you can afford it - yes, you absolutely should get it! Its layout is beautiful, which makes it easier to read than the online version. Also, I personally just like to read a physical copy: my attention span is longer and I tend to take it more seriously. . That being said, you certainly can work with the free online version. It has the added benefit that you will always have the latest version, which is up to date and where bugs are fixed (and there are a few in the book). . . Do I need to know Python? . Yes - or any other language. The book is called &quot;Deep Learning for Coders&quot;, so it will not explain every line of code in detail or teach Python from scratch. In fact, the course website states: . The only prerequisite is that you know how to code (a year of experience is enough), preferably in Python, and that you have at least followed a high school math course. . However, you don&#39;t have to be an expert. When I first started with the course, I only had a few weeks of experience with Python. I did however have some (very basic) experience with web languages like JavaScript and PHP, that helped me pick up Python pretty quickly. If you know any programming language, you won&#39;t have a problem, since Python is rather accessible and has an easy syntax. If you don&#39;t have any programming experience, I recommend investing a few weeks to learn the basics of Python before you tackle fastai. There are wonderful tutorials available for free. . . I&#39;m in! How do I begin? . With lesson 1! 😊 You really can get started right away, the interactive content runs on ready-to-use and free platforms like Google Colab, so you don&#39;t have to spend time setting up your own machine. . The course website gives you an overview of the course (you can read it in addition to this article), then you can start with lesson 1. . I enjoyed combining the videos and the book. After every lesson, I ran the associated notebooks on Colab and then read the chapters in the book. The chapters are very similar to the video lessons, but I think it helps consuming the content in a different medium and being able to go back a few pages if you want to read something again. . My suggestions for efficient learning . Watch the videos twice . I recommend watching the videos twice. On the first view, don&#39;t focus on the details too much, just get an overview of the topics covered and take some notes while doing so. This is especially relevant for the later lessons that contain much more code. On the second view, you can take more detailed notes and try to get all the details. . Take notes! . Taking notes was a gamechanger for me. I think it&#39;s the best way to stay active during the videos, and over time the notes will serve as a central knowledge repository. Also, it&#39;s great to have a place to jot down your questions, so you can try and answer them later! . I keep notes in Microsoft OneNote, you can of course use any other application or paper. I created a template based on this awesome forum post. The template contains following points: . Key Points from the lecture | Advice from Jeremy | To-Do challenges from the further research section of the chapter, ideas for projects | Reading &amp; Exploring papers that are mentioned, stuff you find on the web but don&#39;t have time for at the moment | Questions that arise during the lecture | as the last point, I copy &amp; paste the questionnaire. | . Please read the above-mentioned forum post for details on each section, it&#39;s a really good system. . These notes are meant to be used not just once, but you should refine them and work with them continuously. They can serve you as your go-to resource every time you study. All your open questions, your project ideas, and of course lots of knowledge can live there. . . Don&#39;t get stuck on one thing that you don&#39;t understand . This is an important point and I think Jeremy mentions it as well. You don&#39;t have to understand every detail right away. It&#39;s often better to move on and revisit the part you didn&#39;t quite get later. . Run the code . Jeremy will ask you to do this, and you really should run the notebooks for yourself. I recommend the clean versions, where there is no text, just code. Predict what the output of a cell will be, and if you were wrong, go back and understand why. Just reading the code in the book is not enough, it can give you the illusion that you understood it, when in reality you could not reproduce it. I fell into this trap more than once... . Do the questionnaire . Take the time and answer every question in the questionnaire. This might take a while, but it makes sure that you really understood all important concepts. You can find answers to most questions in the forum. . Additionally, I can recommend aiquizzes.com, where many questions and their answers are made available together with the relevant part of the lecture. You can use this for spaced repetition learning, the website will remind you when older questions need reviewing, it&#39;s great. . Use other sources . Fastai, while being excellent, is not the only source of wisdom. I often google for concepts I don&#39;t quite get. More often than not I find a blog post, a stack overflow answer or a video explaining it very well or with a different approach than Jeremy. . What to do after the course . The course covers only around half the book. There will be a part 2 that covers the more advanced chapters, but as of now (December 2020) there is no release date announced. If you want to dig deeper into the material, you should not wait for the course but work through the book on your own. . In addition, I&#39;d suggest picking a project and make it as good as you can. Go on the forums and see if you can help others, or ask for advice. Write about your journey in your own blog - like the one whose first post you are reading here 😊 . Thank you for reading . Since you made it this far, I hope you found this article interesting and I could get you excited for fast.ai! I really can recommend taking the course and reading the book, and if you put in the time you will see amazing results soon. Let me know if you have any questions or found this article helpful. I&#39;m on Twitter, I&#39;d be happy to hear from you there or via mail at hannes@deeplearning.berlin .",
            "url": "https://deeplearning.berlin/fastai/getting%20started/online%20courses/2020/12/09/Getting-started-with-fastai.html",
            "relUrl": "/fastai/getting%20started/online%20courses/2020/12/09/Getting-started-with-fastai.html",
            "date": " • Dec 9, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi! My name is Johannes Stutz, I usually go with Hannes. I am learning and writing about how machines can learn. My interest in all things AI began with my fascination with Tesla’s Autopilot software. Would it actually be possible for a car to drive itself in every situation? . I wanted to learn more about the technology behind this and have embarked on a journey into machine learning. Since I don’t have a professional background in coding or computer science, I go with “learning by doing”, an approach especially endorsed and offered by fast.ai’s great - and free - online courses. . I work as a pilot for a large airline. I think digitalization and AI can help aviation become more sustainable and even safer. But from my experience with partially automated systems, I also know how important it is to keep the human in the loop. AI should not replace humans, it should support them! . Reach out to me on Twitter, I enjoy talking and learning about machine learning, aviation, space flight… let’s nerd out! . . Thank you . This site is built with fastpages, An easy to use blogging platform with extra features for Jupyter Notebooks. . Thank you Clker-Free-Vector-Images on Pixabay for providing the skyline graphic. . Thank you to wal_172619 on Pixabay for the picture of Berlin TV tower. .",
          "url": "https://deeplearning.berlin/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://deeplearning.berlin/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}