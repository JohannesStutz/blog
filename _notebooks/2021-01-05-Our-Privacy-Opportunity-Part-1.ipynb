{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Privacy Opportunity, Part 1\n",
    "> \"My summary of Lesson 1 & 2 of the first course in The Private AI Series by OpenMined\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: false\n",
    "- categories: [online courses, privacy, the private ai series, openmined]\n",
    "- image: images/articles/2021-01-05-openmined-pt1/title.png\n",
    "- hide: false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I started taking The Private AI Series by OpenMined\n",
    "\n",
    "The series contains four courses, all are free. Only the first one is online at the time of writing (05. Jan 2021).\n",
    "\n",
    "1.\tOur Privacy Opportunity\n",
    "2.\tFoundations of Private Computation\n",
    "3.\tFederated Learning Across Enterprises\n",
    "4.\tFederated Learning on Mobile\n",
    "\n",
    "The first course is non-technical and contains about 8 hours of video, taught by [Emma Bluemke](https://twitter.com/emmabluemke) and [Andrew Trask](https://twitter.com/iamtrask). Additionally, they interview many experts. The course aims to provide a high-level overview of privacy, what it means, where it currently fails, and how possible solutions look. One key point is that there are new privacy-enhancing technologies on the rise that will change the way how humans collaborate. This brings with it many career and business opportunities.\n",
    "\n",
    "If youâ€™re interested, sign up at [courses.openmined.org](https://courses.openmined.org/). I will take at least the first, non-technical course and will decide later whether I dive deeper with the technical courses.\n",
    "\n",
    "Lesson 1 is introductory. This is my summary of Lesson 2 of *Our Privacy Opportunity*, I wrote it for my forgetful self, but maybe it will be helpful for others - so here it is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 1: Society Runs on Information Flows\n",
    "This course is about privacy-transparency trade-offs and how they affect a huge number of problems. This lesson walks through some of the most important challenges to society and identifies how the privacy-transparency tradeoff underpins them. Improving information flows, by solving this tradeoff, can help us in many areas like disinformation, scientific innovation, and even democracy itself.\n",
    "\n",
    "> Important: Information flows are everywhere!\n",
    "\n",
    "We share our medical information with our doctor, we share our location with an app to get directions, we share our heart rates and sleeping patterns in hopes of improving our well-being. Every day, we share personal information to exchange goods, receive services, and in general, to collaborate. Sharing information is a part of almost every aspect of our life. You have to fully grasp this statement to understand how these flows are going to change in the future.\n",
    "\n",
    "Information flows have two fundamental failure modes, where they fail to accomplish their purpose regarding privacy and transparency. These will be covered through case studies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 2: Information Flow\n",
    "What is an information flow? Let's take the simple example of email. A sender, a message, a receiver. Hit send and that's an information flow. But it's much more nuanced than just the three attributes sender, message, receiver: \n",
    "- Should other people than the receiver be allowed to read it?\n",
    "- Would I be comfortable with the receiver forwarding my email, is this the intended information flow?\n",
    "- What about the mail provider, they could probably read it, but I believe they just choose not to.\n",
    "- Do I want the mail provider to read my mail only for a specific purpose, like for spam detection, but not for targeted advertising?\n",
    "- Am I sending my exact identity with the email? Anonymously? Or a mix: as a member of group?\n",
    "- Identity of the recipient: do I know exactly who they are? When I'm sending the mail to a specific group like a doctor's office, who reads it? \n",
    "- But also: can the receiver have confidence in sender identity, whaf if my account was hacked?\n",
    "\n",
    "Sending an email is probably one of the most straight-forward information flows and still there are many questions. These questions and more exist around every information flow.\n",
    "\n",
    "New communication channels emerged. Snapchat deletes the messages once they've been read and prohibits forwarding or screenshotting. WhatsApp or Signal use end-to-end encryption for messages so it's impossible for anyone other than the intended recipient to read them. \n",
    "\n",
    "Users switch to these services because of seemingly tiny changes to the guarantees around information flow.\n",
    "This is the beginning of a revolution!\n",
    "\n",
    "> Important: Every part of the human experience is soaked in information flows. Since the beginning of human collaboration.\n",
    "\n",
    "> Note: A more formal definition: An information flow is a flow of bits from a sender to a receiver. The sender and receiver could either be an exact individual, a member of a group, or an anonymous individual. The identity of the sender, the receiver, and the content of the message itself can be probabilistic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 3: The Privacy Dilemma\n",
    "\n",
    "My location is public information for everybody standing on the same street. So why do I feel uncomfortable with my location being tracked? Or Google Street View: why are people having trouble with Google taking photos of them in their front yard, when anybody could come by and see them exactly there? Because public information can become *so much more public* that it starts to bother us.\n",
    "\n",
    "Privacy is not about secrecy. People feel that their privacy is violated if information flows in a way they didn't expect and didn't like. It's all about appropriateness. Privacy is about flow, not the information itself.\n",
    "\n",
    "> Note: **Conceptual Integrity:** sharing the same information might be private in one context, but not in another context. It's about achieving appropriate information flow.\n",
    "\n",
    "Example: Facial recognition software. My face is public information as soon as I leave the house. So why is facial recognition bad? Not only because it could be misused (mass surveillance), but because I don't consent to the information flow.\n",
    "\n",
    "Two main differences between facial recognition as ID and normal ID:\n",
    "\n",
    "1.\tI can't change my face. If it gets in the wrong hands, you can't just get a new password or credit card.\n",
    "2.\tIt's identification without my consent. The information flow is not triggered by me, but by whatever system is watching me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 4: Data is Fire ðŸ”¥\n",
    "\n",
    "There is the notion that \"data is the new oil\". A better analogy is \"data is like fire\".\n",
    "- It can be duplicated\n",
    "- It can help us prosper and solve problems\n",
    "- It can cause irreparable damage if misused\n",
    "\n",
    "And this dual-use for good or harm is true for all kinds of data, not just data that is clearly sensitive like medical data.\n",
    "\n",
    "### Privacy dilemmas\n",
    "> Note: A privacy dilemma is a trade-off whether to reveal information, where revealing that information causes some social good (like medical research) but could also lead to harm (like the misuse of medical data).\n",
    "\n",
    "Privacy dilemmas have various costs. The most obvious is the possible privacy violation. But there are other, societal costs: a failure to accomplish important outcomes of information flow (scientific progress, meaningful relationships, accountability)\n",
    "\n",
    "> Tip: Privacy dilemmas are untapped market opportunities!\n",
    "\n",
    "### Everything can be private data\n",
    "Your grocery shopping list is boring, right? Not always. You might not care now whether somebody knows you're buying bread. But when you suddenly stop buying bread (and rice and other carbs) it might be an indication of the diagnosis of diabetes. Suddenly it's very private information that you might not want to share.\n",
    "\n",
    "> Warning: Anonymization doesn't work!\n",
    "\n",
    "Even when names are removed from data, other features can be used to identify you, thanks to the power of machine learning (i.e., 5 movies you watched last year and roughly when you watched them).\n",
    "\n",
    "Anonymization works so badly, that systematically exploiting its weaknesses can be a core business model. Emma gives an example of a company that buys anonymized health data and distributes it to insurance companies. They can then for example raise insurance costs for high-risk communities like poor neighborhoods that are more likely to get sick. Harm is done without knowing any one individual! \n",
    "\n",
    "Another example: Strava released an anonymized heatmap that revealed home addresses of individuals (because they cycle from home to work) and the location of US military bases. So, privacy can be relevant not only on an individual level but on an organizational or even national security level.\n",
    "\n",
    "### Targeting\n",
    "Acting on information. Advertisement, targeted disinformation, shaming, fraud, physical harm. Pinpointing someone's identity might not even be necessary. As long as someone is able to reach you (via your browser, your church, your neighborhood, ...), your name is absolutely not necessary to do harm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 5: The Transparency Dilemma\n",
    "\n",
    "> Info: A transparency dilemma is when someone is forced to make a decision without having access to the information they need to make it.\n",
    "\n",
    "Sometimes the information flows don't exist at all (trusting a stranger to fix your tire), sometimes they are not verified (online reviews).\n",
    "\n",
    "The solution to privacy is not to stop all information flow, lock all data. This would prevent good use of data (think medical care, climate research) and also make it easier to have undesirable outcomes (money laundering, lack of accountability). Maximizing privacy could lead to a lack of transparency!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 6: The Privacy-Transparency Pareto Frontier\n",
    "\n",
    "<img src=\"../images/articles/2021-01-05-openmined-pt1/privacy-transparency.png\" width=\"400\" />\n",
    "\n",
    "We used to have a classic trade-off between privacy and transparency. If you made all data private, you would have solved the privacy dilemma, but there would not be any transparency. If you made everything public, there would be no transparency dilemma, but no privacy left. With new technologies, you can actually move the pareto trade-off and have more of both, simultaneously!\n",
    "\n",
    "<img src=\"../images/articles/2021-01-05-openmined-pt1/privacy-transparency-up.png\" width=\"400\" />\n",
    "\n",
    "This will have downstream effects on every industry handling valuable, sensitive, or private data.\n",
    "\n",
    "Governments don't have to choose between preserving the privacy of their citizens or protect national security, now they can do both. Researchers don't have to decide whether or not to share their data, now they can have the benefits from both. Corporations previously had to choose between the privacy of their users and the accuracy of their products and services, now they can have the benefits of both.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 7: Research is Constrained by Information Flows\n",
    "\n",
    "Research would profit if data could be more easily shared. More data would be available, it would be available faster, and experiments could be replicated easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 8: Healthy Market Competition for Information Services\n",
    "\n",
    "Most services that handle your data are, per default, services that lock you in. Because of privacy concerns, they are inherently anti-competitive. And more intense privacy restrictions actually make it harder for other new companies to compete (because you can't move your data to another provider).\n",
    "\n",
    "GDPR in the EU: a groundbreaking piece of legislation that is being copied around the world.\n",
    "\n",
    "People now have rights over their data. For example:\n",
    "- Right to be forgotten\n",
    "- Right to see which data a company has of them\n",
    "\n",
    "Interoperability: You should be able to move to a different company and take your data with you. Endless business opportunities.\n",
    "\n",
    "> Important: Privacy is not only about preventing information from being shared. Sometimes satisfying privacy is about forcing companies to share or delete your data in a specific way or at a specific time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 9: Data, Energy, and the Environment\n",
    "\n",
    "Example: Smart meters can be highly valuable for the switch to renewable energy. But they can also be extremely privacy invasive, because you can build rich patterns on how your daily habits are, when you are or are not at home etc.\n",
    "\n",
    "In Taiwan, there was a movement to provide air quality measurements through \"Air Boxes\" throughout the country. The government didn't invest heavily in this technology, but private citizens did. And they were able to coordinate with millions of people to get this system working!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 10: Feedback Mechanisms & Information Flows\n",
    "\n",
    "Feedback mechanisms today are often broken or non-existent. Examples:\n",
    "\n",
    "Consumer products: How do I know whether a product is any good? Amazon Reviews are easy to fake, and the real ones come from only the most polarized users\n",
    "\n",
    "Politics: A multiple choice question between a few candidate every 4 years is a *terrible* feedback system for reviewing the legislature of the past 4 years.\n",
    "\n",
    "Public safety: safety and security are not achieved by a lot of police, but by \"eyes on the street\", normal people watching out. It's at the same time *more effective* than a government-lead approach, and *less intrusive*! Some of the safest countries, like Taiwan, have among the lowest numbers of police per capita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 11: Democracy & Public Health Conversation\n",
    "\n",
    "Democracy is messy. Opinions are formed via social groups. In recent years, there was an uptick in polarization, one of the reasons probably being social media, where algorithms maximize engagement.\n",
    "\n",
    "A better way can be found in Taiwan, with the *Polis* system. A community-built, nation-wide application that supports conversation between millions of users in Taiwan. It's not optimized for *engagement*, but for *consensus*. People can enter their opinions in written form (tweet-like), and a combination of NLP and voting clusters these opinions. Turns out, opinions aren't actually individual. There are less opinions than there are people because opinions are formed socially. However, the social groups that form our opinions aren't fixed but constantly changing.\n",
    "\n",
    "So, some people emerge as being representative for specific opinions and become thought leaders for this particular matter. But now they must come up with a formulation that will get the most consent *across opinions*! \\[Not sure if I got this exactly right\\]\n",
    "\n",
    "Example: Uber wanted to come to Taiwan. Very polarized opinions. The solution was: Uber was permitted a temporary license in Taiwan. During this time, the public Taxi sector should adopt the efficient, algorithmic approaches from Uber while maintaining labor standards. If they would succeed, Uber would be banned. If they failed, Uber would be banned unless they met the labor standards of the public system. That put just enough pressure on both sides, and in the end, the public system did improve so much that Uber was excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 12: New Market Incentives\n",
    "\n",
    "Many online (information-based) companies rely on attention (engagement) as their key metric. For some, this makes intuitive sense because their revenue is ad-driven. But even companies that run on a subscription model, like Netflix, do it. The Netflix CEO even said, they are competing with the time you spend sleeping. The question is: why?\n",
    "\n",
    "One answer is, it's a readily available metric that is fine-grained and allows for optimization. If Netflix just used the number of subscribers (and that's the value they actually try to increase), it would be too coarse. Only if a movie was that good or that bad that users actually subscribed/unsubscribed it would be measurable. \n",
    "\n",
    "Attention as a metric does work, and it is probably fine at a small scale. But at large scale and taken to the extremes it can cause harm, see the Netflix/sleep example.\n",
    "\n",
    "A better way: Netflix could try to optimize their experience to improve the users' sleep. But how would they measure it and train an algorithm on it? Fitbits track sleep but is it safe to share this data with Netflix?\n",
    "In general, these alternative metrics are called wellness metrics and can improve our lives.\n",
    "\n",
    "> Tip: Technology isn't inherently addictive! Better products are possible.\n",
    "\n",
    "But we need to solve the privacy-transparency trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 13: Safe Data Networks for Business, Governance and R&D\n",
    "\n",
    "Free/easy (?) information flow across EU states was proposed. When a company wants to introduce a product in all member states of the EU, it needs data from all these states to customize its product. So, for example a company in France needs data from Germany.\n",
    "\n",
    "But, as shown in Concept 4, new mathematical tools allow reconstruction of personal details even from anonymized datasets. Therefore, we need to build trust to allow sharing of sensitive data.\n",
    "\n",
    "Today, there is the technology available that allows privacy-preserving data analysis. Imagine the data in question never actually moves. It would remain on a server in Germany, but the French company could still work with it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 14: Conflict, Political Science & Information Flows\n",
    "\n",
    "One rational explanation of war: Mutual Optimism. It's extremely hard to predict the outcome of a battle, a war. Both sides come up with an estimate that says, \"we're more likely than not to win\". The sum of the estimates is greater than 1. And that's why nations go to war.\n",
    "\n",
    "A way to share private military information to determine the winner (in a digital war game) without actually giving the opponent this information could potentially avoid wars.\n",
    "\n",
    "This is true for other conflicts as well, legal disputes, commercial competition. If the winner could be determined ahead some conflicts wouldn't be fought.\n",
    "\n",
    "Moving the privacy-transparency trade-off is essential here as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 15: Disinformation & Information Flows\n",
    "\n",
    "The flow of news is one of the most important information flows in the world. How do you know that what you read in the news is actually true?\n",
    "\n",
    "Naturally, before the invention of the printing press, people had the power to talk to maybe 50 people at the same time. For a story to be shared outside your own social circle, you would have to convince other people to talk about it. Very comparable to the R number in infectious diseases. A baseless rumor might have a natural R value of 0.01 (1 in a 100 people would spread it). But today, where the average person has hundreds of contacts on social media, the R value is easily 10s or 100s of times bigger and fake news and rumors can spread.\n",
    "\n",
    "How to check if news is true?\n",
    "- Just wait for humans to adjust to the internet? Bad idea, when we look at the printing press, it took hundreds of years and many conflicts until humans adjusted to it.\n",
    "- Have social media platforms check every bit that is published? Not feasible for hundreds of millions of users.\n",
    "- Have AI and machine learning check whether a piece of news is true? Probably a bad idea in the long run, because news is an information bottleneck. You receive a text message \"I love you\". Can you tell whether it's true just by looking at it? No! You have to have knowledge of the world. So, detecting fake news just by reading it is impossible (you could randomly generate a story that actually happened in the real world).\n",
    "- Just get off social media? Maybe we're just not supposed be interconnected with that many people?\n",
    "\n",
    "The most interesting solution is currently being deployed in Taiwan:\n",
    "\n",
    "A platform (g0v, pronounced \"gov zero\") that people interact on, and trained volunteers comment on suspicious stories with other sources one might check. Because these comments come from people that you actually know or from your local community, not from a state's official or a platform, you already have a level of trust.\n",
    "\n",
    "Two groups of ideas that seem to work highly effective:\n",
    "\n",
    "1.\tIt's not so much about detecting misinformation and taking it down. It's more about fostering a national community that helps each other filter between truths and lies. People are relying on existing interpersonal relationships, instead of having to trust the state or the platform.\n",
    "2.\tTaiwan is using technology and intentional narratives such as humor to foster trust between civil society and the state. Humor over rumor!\n",
    "\n",
    "> Important: It's incredibly important to consider how societies historically dealt with misinformation.\n",
    "\n",
    "It doesn't fix the problem to let the platforms take down false posts. People are curious and won't just accept this as \"huh, this is false then\".\n",
    "\n",
    "The beauty of Audrey Tang's work (g0v): constructing information flows that are healthy for society. Not thinking about the most efficient way to prevent a data flow. But to activate existing ways to prevent disinformation: get people to help their friends and use humor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The privacy-transparency trade-off or even privacy in general is in service of a higher aim: creating information flows within society that creates social good. This is the true aim.\n",
    "\n",
    "> Important: Privacy technology is not just about privacy!\n",
    "\n",
    "Don't sit and look for use cases that scream \"privacy\". This is totally defensive. Instead, ask the questions:\n",
    "How can society accomplish its goals with less risk, higher accuracy, faster, and with better aligned incentives than ever before, through better flows of information. \n",
    "\n",
    "That is the promise of privacy-enhancing technology and has the potential to radically improve every aspect of how we share information.\n",
    "\n",
    "> Tip: Entrepreneurial opportunities, regulatory opportunities, investing opportunities:\n",
    "It's not about hiding data; it's about enabling specific information flows (and just these!) to maximize social good.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
